{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiet6\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiet6\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models, scaler, and label encoder have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract metadata from a WAV file\n",
    "def getmetadata(filename):\n",
    "    y, sr = librosa.load(filename)\n",
    "\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    metadata_dict = {'tempo': tempo, 'chroma_stft': np.mean(chroma_stft), 'rmse': np.mean(rmse),\n",
    "                     'spectral_centroid': np.mean(spec_centroid), 'spectral_bandwidth': np.mean(spec_bw),\n",
    "                     'rolloff': np.mean(spec_rolloff), 'zero_crossing_rates': np.mean(zero_crossing)}\n",
    "\n",
    "    for i in range(1, 21):\n",
    "        metadata_dict.update({'mfcc' + str(i): np.mean(mfcc[i - 1])})\n",
    "\n",
    "    return list(metadata_dict.values())\n",
    "\n",
    "# 2. Loading the dataset\n",
    "df = pd.read_csv(\"music_classification.csv\")\n",
    "X = df.iloc[:, 1:28]\n",
    "y = df['class_name']\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# 3. Preprocessing the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, stratify=y)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Hyperparameter tuning for models\n",
    "# SVM\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "param_svm = {'C': [0.1, 1, 10, 100]}\n",
    "svm_search = RandomizedSearchCV(svm, param_svm, n_iter=10, scoring='accuracy', cv=5, random_state=3)\n",
    "svm_search.fit(X_train_scaled, y_train)\n",
    "svm_best = svm_search.best_estimator_\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "param_knn = {'n_neighbors': range(1, 31)}\n",
    "knn_search = RandomizedSearchCV(knn, param_knn, n_iter=10, scoring='accuracy', cv=5, random_state=3)\n",
    "knn_search.fit(X_train_scaled, y_train)\n",
    "knn_best = knn_search.best_estimator_\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "param_logreg = {'C': [0.1, 1, 10, 100]}\n",
    "logreg_search = RandomizedSearchCV(logreg, param_logreg, n_iter=10, scoring='accuracy', cv=5, random_state=3)\n",
    "logreg_search.fit(X_train_scaled, y_train)\n",
    "logreg_best = logreg_search.best_estimator_\n",
    "\n",
    "# XGBoost\n",
    "xgbc = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "param_xgbc = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "xgbc_search = RandomizedSearchCV(xgbc, param_xgbc, n_iter=10, scoring='accuracy', cv=5, random_state=3)\n",
    "xgbc_search.fit(X_train_scaled, y_train)\n",
    "xgbc_best = xgbc_search.best_estimator_\n",
    "\n",
    "# 5. Ensemble model\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('svm', svm_best), \n",
    "    ('knn', knn_best), \n",
    "    ('logreg', logreg_best), \n",
    "    ('xgbc', xgbc_best)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Saving the trained models using pickle\n",
    "with open('pickle/ensemble_model.pkl', 'wb') as file:\n",
    "    pickle.dump(ensemble, file)\n",
    "\n",
    "# Save the scaler and label encoder as well\n",
    "with open('pickle/scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "with open('pickle/label_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)\n",
    "\n",
    "print(\"Models, scaler, and label encoder have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Loading the dataset\n",
    "df = pd.read_csv(\"music_classification.csv\")\n",
    "X = df.iloc[:, 1:28]\n",
    "y = df['class_name']\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
